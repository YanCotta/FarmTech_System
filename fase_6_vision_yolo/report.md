# Relat√≥rio de Projeto Completo: Vis√£o Computacional FarmTech Solutions

**üé• [V√≠deo Demonstrativo](https://youtu.be/LlLFZXPC-bU)**

**Projeto:** Solu√ß√£o Completa de Vis√£o Computacional - Detec√ß√£o e Classifica√ß√£o de Objetos
**Equipe FarmTech Vision Lab:**
- Yan Pimentel Cotta - RM: 562836
- Jonas T V Fernandes - RM: 563027
- Raphael da Silva - RM: 561452
- Raphael Dinelli Neto - RM: 562892
- Levi Passos Silveira Marques - RM: 565557

**Per√≠odo de Desenvolvimento:** Outubro de 2025
**Tecnologias:** Python, YOLOv5, PyTorch, TensorFlow/Keras, MobileNetV2, Google Colab, Google Drive, Make Sense AI

**Documenta√ß√£o relacionada:** 
- Vis√£o geral: [README](../README.md)
- Orienta√ß√µes oficiais: [orientation.md](orientation.md)
- Notebooks execut√°veis: 
  - [`entregavel_1_fase6_cap1.ipynb`](../notebooks/entregavel_1_fase6_cap1.ipynb) (Entrega 1)
  - [`Entrega2_RaphaelDaSilva_RM561452_fase6_cap1.ipynb`](../notebooks/Entrega2_RaphaelDaSilva_RM561452_fase6_cap1.ipynb) (Entrega 2)
  - [`ir_alem_opcao_2_fase_6_cap1.ipynb`](../notebooks/ir_alem_opcao_2_fase_6_cap1.ipynb) (Ir Al√©m 2)

---

## **1.0 Resumo Executivo**

Este relat√≥rio documenta o desenvolvimento de uma solu√ß√£o completa de vis√£o computacional para a FarmTech Solutions, apresentando tr√™s entregas complementares que exploram diferentes aspectos de detec√ß√£o e classifica√ß√£o de objetos utilizando Deep Learning. O projeto foi desenvolvido ao longo da Fase 6 do curso de IA/ML da FIAP, seguindo rigorosamente as orienta√ß√µes estabelecidas no documento [`orientation.md`](orientation.md).

### Vis√£o Geral das Entregas

**Entrega 1 - Detec√ß√£o Customizada com YOLOv5:**
A primeira entrega estabeleceu a base do projeto com uma Prova de Conceito (PoC) completa de detec√ß√£o de objetos. Foram conduzidos tr√™s experimentos controlados ‚Äî dois com a arquitetura **YOLOv5s** (30 e 60 √©pocas) e um com a arquitetura **YOLOv5m** (60 √©pocas) ‚Äî para detectar objetos das classes `banana` e `fork`. O modelo campe√£o (`YOLOv5m`) alcan√ßou **mAP@.50 geral de 0.789**, com desempenho praticamente perfeito na classe `banana` (0.995) e avan√ßo significativo na classe `fork` (0.584).

**Entrega 2 - Compara√ß√£o YOLO vs CNN:**
A segunda entrega expandiu a an√°lise atrav√©s de um estudo comparativo entre a arquitetura YOLOv5 (focada em detec√ß√£o) e uma Rede Neural Convolucional customizada (focada em classifica√ß√£o). A CNN foi desenvolvida do zero e treinada em dois cen√°rios (30 e 60 √©pocas), permitindo uma avalia√ß√£o criteriosa dos trade-offs entre facilidade de uso, precis√£o, tempo de treinamento e aplicabilidade de cada abordagem.

**Ir Al√©m 2 - Pipeline Integrado com Transfer Learning:**
A entrega adicional demonstrou t√©cnicas avan√ßadas atrav√©s de um pipeline de duas etapas que combina YOLOv5 para detec√ß√£o de ROI (Regi√£o de Interesse) com MobileNetV2 para classifica√ß√£o via transfer learning. Esta abordagem h√≠brida resultou em melhorias significativas de acur√°cia (+12.50 pontos) e precis√£o (+17.86 pontos) em compara√ß√£o com classifica√ß√£o direta.

### Principais Conquistas
- Dataset propriet√°rio de 80 imagens com alta variabilidade de condi√ß√µes
- Pipeline completo de MLOps desde coleta at√© deploy
- An√°lise quantitativa e qualitativa detalhada de m√∫ltiplas arquiteturas
- Documenta√ß√£o executiva alinhada √†s melhores pr√°ticas de governan√ßa
- Recomenda√ß√µes estrat√©gicas para diferentes cen√°rios de implanta√ß√£o

---

## **2.0 Metodologia e Plano de A√ß√£o**

O projeto seguiu rigorosamente as orienta√ß√µes estabelecidas no documento [`orientation.md`](orientation.md), que define os requisitos, metas e entreg√°veis para a Fase 6 do curso. A metodologia adotada segue as melhores pr√°ticas de desenvolvimento de modelos de Machine Learning, com √™nfase em reprodutibilidade, documenta√ß√£o e governan√ßa.

### 2.1 Alinhamento com Requisitos da Fase 6

Conforme especificado nas orienta√ß√µes, o projeto atende aos seguintes requisitos:

**Metas da Entrega 1 (Atendidas):**
- ‚úÖ Dataset com m√≠nimo de 40 imagens por classe (A e B), totalizando 80 imagens
- ‚úÖ Divis√£o estratificada: 32 imagens/classe para treino, 4 para valida√ß√£o, 4 para teste
- ‚úÖ Armazenamento no Google Drive com separa√ß√£o adequada
- ‚úÖ Rotula√ß√£o no Make Sense AI com exporta√ß√£o para formato YOLO
- ‚úÖ Notebook no Google Colab com documenta√ß√£o Markdown completa
- ‚úÖ M√∫ltiplas simula√ß√µes com diferentes √©pocas (30 e 60) comparando acur√°cia e desempenho
- ‚úÖ Apresenta√ß√£o de conclus√µes sobre valida√ß√£o e testes
- ‚úÖ Prints das imagens processadas demonstrando resultados

**Entreg√°veis da Entrega 1 (Cumpridos):**
- ‚úÖ Reposit√≥rio GitHub p√∫blico com nome do grupo (FarmTech Vision Lab)
- ‚úÖ Notebook com c√≥digo executado e c√©lulas Markdown organizadas
- ‚úÖ V√≠deo demonstrativo de at√© 5 minutos no YouTube (n√£o listado)
- ‚úÖ README com documenta√ß√£o introdut√≥ria integrada ao notebook
- ‚úÖ Reposit√≥rio mantido p√∫blico para acesso da equipe FIAP

### 2.2 Fases de Execu√ß√£o do Projeto

**Fase 0: Setup e Funda√ß√£o do Ambiente**
- Configura√ß√£o do versionamento de c√≥digo (Git/GitHub)
- Estrutura√ß√£o de armazenamento de dados (Google Drive com hierarquia `/datasets/images/` e `/datasets/labels/`)
- Configura√ß√£o do ambiente de desenvolvimento (Google Colab com GPU T4)

**Fase 1: Aquisi√ß√£o e Prepara√ß√£o dos Dados**
- Sele√ß√£o estrat√©gica dos objetos (`banana` e `fork`) baseada em distin√ß√£o visual e disponibilidade
- Coleta de dataset propriet√°rio com 80 imagens (40 por classe)
- Captura com variabilidade controlada de √¢ngulos, ilumina√ß√£o e fundos
- Divis√£o estratificada: 64 treino (80%), 8 valida√ß√£o (10%), 8 teste (10%)

**Fase 2: Anota√ß√£o dos Dados**
- Rotula√ß√£o manual no Make Sense AI usando bounding boxes retangulares
- Exporta√ß√£o para formato YOLO (arquivos .txt com coordenadas normalizadas)
- Valida√ß√£o de integridade das anota√ß√µes
- Armazenamento sincronizado com Google Drive

**Fase 3: Desenvolvimento e Treinamento**
- **Entrega 1**: Tr√™s experimentos controlados com YOLOv5
  - YOLOv5s com 30 √©pocas (baseline)
  - YOLOv5s com 60 √©pocas (avaliar impacto de √©pocas adicionais)
  - YOLOv5m com 60 √©pocas (avaliar impacto de arquitetura maior)
- **Entrega 2**: Compara√ß√£o com CNN customizada
  - Desenvolvimento de arquitetura sequencial do zero
  - Treinamento com 30 e 60 √©pocas
- **Ir Al√©m 2**: Pipeline integrado avan√ßado
  - Transfer learning com MobileNetV2
  - Pr√©-processamento inteligente com YOLOv5

**Fase 4: An√°lise e Avalia√ß√£o**
- An√°lise quantitativa: m√©tricas de mAP@.50, precis√£o, recall, F1-score
- An√°lise qualitativa: inspe√ß√£o visual das predi√ß√µes
- Compara√ß√£o de trade-offs: acur√°cia vs custo computacional vs tamanho do modelo
- Documenta√ß√£o detalhada de limita√ß√µes e desafios encontrados

**Fase 5: Infer√™ncia e Valida√ß√£o Final**
- Teste em conjunto de imagens nunca vistas durante treinamento
- Valida√ß√£o da capacidade de generaliza√ß√£o
- Gera√ß√£o de visualiza√ß√µes e relat√≥rios de resultados

**Fase 6: Empacotamento e Entrega**
- Finaliza√ß√£o da documenta√ß√£o executiva (README.md e report.md)
- Produ√ß√£o de v√≠deos demonstrativos
- Gera√ß√£o de gr√°ficos comparativos e tabelas executivas
- Submiss√£o via portal FIAP

---

## **3.0 Execu√ß√£o Detalhada do Projeto (Changelog)**

### 3.1 Entrega 1: Detec√ß√£o Customizada com YOLOv5

**Setup do Ambiente:**
- Inicializado reposit√≥rio GitHub (YOLO_vision_demo) com template `.gitignore` para Python
- Estruturada hierarquia de pastas no Google Drive: `/datasets/images/` e `/datasets/labels/`
- Configurado Google Colab com GPU T4 para treinamento acelerado
- Clonado reposit√≥rio oficial do YOLOv5 da Ultralytics

**Aquisi√ß√£o de Dados:**
- Selecionadas classes `banana` e `fork` por distin√ß√£o visual e disponibilidade f√≠sica
- Coletadas 80 imagens propriet√°rias (40 por classe) com variabilidade de:
  - √Çngulos de captura (frontal, lateral, diagonal)
  - Condi√ß√µes de ilumina√ß√£o (natural, artificial, mista)
  - Fundos diversos (uniforme, texturizado, complexo)
- Divis√£o estratificada 80/10/10: 64 treino, 8 valida√ß√£o, 8 teste

**Anota√ß√£o de Dados:**
- Rotulagem no Make Sense AI com bounding boxes retangulares
- Exporta√ß√£o para formato YOLO (arquivos .txt com coordenadas normalizadas)
- Primeira tentativa usou pol√≠gonos (incompat√≠vel) - re-anota√ß√£o necess√°ria
- 72 imagens anotadas (treino + valida√ß√£o)

**Treinamento e Experimenta√ß√£o:**
- **Experimento 1 - YOLOv5s 30 √©pocas**:
  - Peso inicial: `yolov5s.pt` (pr√©-treinado em COCO)
  - Tempo de treino: 0.56h (CPU, primeiro experimento)
  - mAP@.50 geral: 0.393
  - mAP@.50 banana: 0.687 | fork: 0.0999
  - Tamanho do modelo: 14.4 MB
  
- **Experimento 2 - YOLOv5s 60 √©pocas**:
  - Peso inicial: `yolov5s.pt`
  - Tempo de treino: 1.13h (CPU)
  - mAP@.50 geral: 0.513 (+30.5% vs Exp1)
  - mAP@.50 banana: 0.764 | fork: 0.262
  - Tamanho do modelo: 14.4 MB
  
- **Experimento 3 - YOLOv5m 60 √©pocas** (Modelo Campe√£o):
  - Peso inicial: `yolov5m.pt`
  - Tempo de treino: 0.13h (GPU T4)
  - mAP@.50 geral: 0.789 (+53.8% vs melhor YOLOv5s)
  - mAP@.50 banana: 0.995 | fork: 0.584
  - Tamanho do modelo: 42.2 MB

**Infer√™ncia e Valida√ß√£o:**
- Testes realizados no conjunto separado (8 imagens)
- An√°lise qualitativa com visualiza√ß√µes de bounding boxes
- Gera√ß√£o de gr√°ficos comparativos de m√©tricas
- Exporta√ß√£o de artefatos para Google Drive

**Produtos Gerados:**
- Notebook completo com c√©lulas Markdown narrativas
- V√≠deo demonstrativo de 5 minutos no YouTube
- Gr√°ficos: curvas de aprendizado, comparativo de barras, curvas de perda
- Tabela comparativa executiva dos tr√™s experimentos

### 3.2 Entrega 2: Compara√ß√£o YOLO vs CNN

**Desenvolvimento da CNN:**
- Arquitetura sequencial customizada desenvolvida no Keras:
  - Camadas Conv2D com 32 e 64 filtros (kernel 3√ó3, ReLU)
  - MaxPooling 2√ó2 para redu√ß√£o de dimensionalidade
  - Flatten + Dense (128 neur√¥nios, ReLU)
  - Dropout (0.5) para regulariza√ß√£o
  - Camada de sa√≠da Dense (2 neur√¥nios, Softmax)
- Compila√ß√£o: otimizador Adam, loss categorical crossentropy
- Imagens redimensionadas para 150√ó150 pixels

**Treinamento da CNN:**
- **CNN 30 √©pocas**:
  - Acur√°cia treino: ~97%
  - Acur√°cia valida√ß√£o: ~84%
  - Observadas oscila√ß√µes entre √©pocas
  
- **CNN 60 √©pocas**:
  - Acur√°cia treino: ~97%
  - Acur√°cia valida√ß√£o: ~95.9%
  - Melhor estabilidade e generaliza√ß√£o

**An√°lise Comparativa:**
Compara√ß√£o sistem√°tica entre YOLO e CNN considerando:
- **Facilidade de uso**: YOLO com ferramentas prontas vs CNN que requer implementa√ß√£o manual
- **Precis√£o**: YOLO superior para detec√ß√£o multi-objeto, CNN adequada para classifica√ß√£o
- **Tempo de treinamento**: CNN mais r√°pida devido √† simplicidade arquitetural
- **Tempo de infer√™ncia**: YOLO otimizada para tempo real, CNN eficiente para classifica√ß√£o pura

**Conclus√µes da Entrega 2:**
- YOLOv5 demonstrou superioridade para detec√ß√£o de objetos em tempo real
- CNN mais adequada para tarefas de classifica√ß√£o onde localiza√ß√£o n√£o √© necess√°ria
- Trade-offs claros entre complexidade de implementa√ß√£o e versatilidade

### 3.3 Ir Al√©m 2: Pipeline Integrado com Transfer Learning

**Abordagem 1 - Baseline (MobileNetV2 puro):**
- Modelo pr√©-treinado no ImageNet
- Fine-tuning das camadas superiores
- Treinamento em dataset completo sem pr√©-processamento
- Resultados baseline:
  - Acur√°cia: 75%
  - Precis√£o: 67.86%
  - Recall: 100%

**Abordagem 2 - Pipeline Integrado:**
- **Etapa 1**: YOLOv5 para detec√ß√£o e recorte de ROI
  - Uso do modelo treinado na Entrega 1
  - Identifica√ß√£o autom√°tica de objetos nas imagens
  - Recorte inteligente da regi√£o de interesse
- **Etapa 2**: MobileNetV2 para classifica√ß√£o
  - Classifica√ß√£o sobre ROIs extra√≠das
  - Redu√ß√£o de ru√≠do de fundo
  - Foco na regi√£o relevante do objeto

**Resultados do Pipeline Integrado:**
- Acur√°cia: 87.50% (+12.50 pontos vs baseline)
- Precis√£o: 85.71% (+17.86 pontos vs baseline)
- Recall: 75% (-25 pontos vs baseline)

**An√°lise de Trade-offs:**
- Ganho significativo em precis√£o (menos falsos positivos)
- Redu√ß√£o em recall indica falhas na detec√ß√£o inicial (YOLOv5)
- Pipeline mais complexo mas com melhor confiabilidade
- Adequado para aplica√ß√µes onde precis√£o √© cr√≠tica

**Recomenda√ß√µes:**
- Pipeline integrado para contextos que exigem alta confiabilidade
- Baseline direto para m√°xima cobertura (recall)
- Possibilidade de ajuste de thresholds conforme necessidade do neg√≥cio

---

## **4.0 Desafios Encontrados e Solu√ß√µes Aplicadas**

### 4.1 Desafios da Entrega 1

**Desafio 1: Incompatibilidade de Anota√ß√£o (Pol√≠gonos vs. Bounding Boxes)**
- **Problema:** Primeira tentativa de anota√ß√£o utilizou pol√≠gonos para maximizar precis√£o. O Make Sense AI n√£o suporta exporta√ß√£o de pol√≠gonos para formato YOLO, que requer estritamente bounding boxes retangulares.
- **Solu√ß√£o:** Re-anota√ß√£o completa do dataset (72 imagens) utilizando ferramenta de bounding box.
- **Aprendizado:** Cr√≠tico alinhar metodologia de anota√ß√£o com requisitos de entrada do modelo antes de iniciar trabalho manual. Esta experi√™ncia refor√ßou import√¢ncia de validar compatibilidade de ferramentas no in√≠cio do pipeline.
- **Impacto:** Atraso de aproximadamente 4 horas no cronograma, mas garantiu compatibilidade total com YOLOv5.

**Desafio 2: Perda de Contexto de Diret√≥rio no Colab**
- **Problema:** Ap√≥s interrup√ß√£o de c√©lula de treinamento, ambiente Colab perdeu contexto do diret√≥rio de trabalho (`/content/yolov5/`), causando `FileNotFoundError` ao reexecutar `train.py`.
- **Solu√ß√£o:** Adi√ß√£o de comando `%cd /content/yolov5/` no in√≠cio de todas as c√©lulas de execu√ß√£o de scripts, garantindo diret√≥rio correto independente do estado da sess√£o.
- **Aprendizado:** Import√¢ncia de tornar notebooks robustos contra interrup√ß√µes, especialmente em ambientes de nuvem com timeouts.

**Desafio 3: Formato de Imagem Inv√°lido (.AVIF)**
- **Problema:** Durante treinamento, YOLOv5 emitiu avisos sobre duas imagens `.AVIF` que n√£o puderam ser lidas e foram ignoradas.
- **Solu√ß√£o:** Identifica√ß√£o e convers√£o das imagens para formatos padr√£o (`.jpg` ou `.png`). Treinamento prosseguiu com dataset reduzido, mas corre√ß√£o implementada para futuras itera√ß√µes.
- **Aprendizado:** Necessidade de valida√ß√£o de formatos de imagem antes do treinamento. Implementa√ß√£o de script de verifica√ß√£o autom√°tica recomendada para futuros projetos.

**Desafio 4: Limita√ß√µes de Bounding Boxes para Geometrias Irregulares**
- **Problema:** Objetos com geometria irregular (garfos angulados, bananas curvas) sofrem com representa√ß√£o em bounding boxes retangulares, que capturam excesso de fundo e reduzem raz√£o sinal-ru√≠do.
- **Impacto:** Classe `fork` apresentou desempenho inferior (mAP@.50 de 0.584 no melhor modelo vs 0.995 para `banana`).
- **Mitiga√ß√£o Parcial:** Arquitetura YOLOv5m mais robusta melhorou significativamente detec√ß√£o de `fork` (0.0999 ‚Üí 0.584).
- **Roadmap Futuro:** Considerar segmenta√ß√£o de inst√¢ncias (Mask R-CNN, YOLACT) para objetos irregulares.

### 4.2 Desafios da Entrega 2

**Desafio 5: Compara√ß√£o entre Tarefas Diferentes (Detec√ß√£o vs Classifica√ß√£o)**
- **Problema:** YOLO realiza detec√ß√£o de objetos (localiza√ß√£o + classifica√ß√£o) enquanto CNN faz apenas classifica√ß√£o. Compara√ß√£o direta de m√©tricas pode ser enganosa.
- **Solu√ß√£o:** An√°lise focada em diferentes aspectos: YOLO avaliado por mAP, precision, recall para detec√ß√£o; CNN avaliada por acur√°cia de classifica√ß√£o. Compara√ß√£o contextualizada no dom√≠nio de aplica√ß√£o.
- **Aprendizado:** Import√¢ncia de definir m√©tricas apropriadas para cada arquitetura e contexto de uso.

**Desafio 6: Overfitting em CNN Simples**
- **Problema:** CNN com arquitetura simples apresentou sinais de overfitting com alta acur√°cia de treino (97%) mas acur√°cia de valida√ß√£o vari√°vel.
- **Solu√ß√£o:** Adi√ß√£o de camada Dropout (0.5) e aumento do n√∫mero de √©pocas para 60, melhorando estabilidade.
- **Resultado:** Acur√°cia de valida√ß√£o estabilizou em ~95.9%.

### 4.3 Desafios do Ir Al√©m 2

**Desafio 7: Trade-off Precision vs Recall no Pipeline Integrado**
- **Problema:** Pipeline YOLOv5 + MobileNetV2 mostrou excelente precis√£o (85.71%) mas recall reduzido (75% vs 100% no baseline).
- **Causa Raiz:** Falhas na detec√ß√£o inicial pelo YOLOv5 resultam em perda de objetos antes da classifica√ß√£o.
- **An√°lise:** Este n√£o √© uma falha, mas um insight valioso sobre din√¢mica entre confiabilidade e abrang√™ncia.
- **Recomenda√ß√£o:** Para contextos cr√≠ticos onde falsos positivos s√£o custosos, usar pipeline integrado. Para m√°xima cobertura, usar baseline direto.

**Desafio 8: Complexidade Computacional do Pipeline**
- **Problema:** Pipeline de duas etapas requer mais recursos e tempo de infer√™ncia que classifica√ß√£o direta.
- **Impacto:** Tempo de infer√™ncia aproximadamente 2x maior.
- **Justificativa:** Ganho de +17.86 pontos em precis√£o justifica overhead para aplica√ß√µes que exigem alta confiabilidade.
- **Otimiza√ß√£o Futura:** Considerar batch processing e otimiza√ß√µes de modelo (quantiza√ß√£o, pruning).

---

## **5.0 An√°lise de Resultados**

### 5.1 Resultados da Entrega 1: Detec√ß√£o YOLOv5

**Comparativo de Desempenho dos Tr√™s Experimentos:**

| M√©trica               | YOLOv5s 30 √âpocas | YOLOv5s 60 √âpocas | YOLOv5m 60 √âpocas | An√°lise |
| --------------------- | -----------------: | -----------------: | -----------------: | ------- |
| **mAP@.50 (Geral)**   | 0.393 | 0.513 | **0.789** | Modelo m√©dio superior em 53.8% |
| mAP@.50 (banana)      | 0.687 | 0.764 | **0.995** | Praticamente saturado |
| mAP@.50 (fork)        | 0.0999 | 0.262 | **0.584** | Melhora dram√°tica: 484% |
| Tamanho modelo (MB)   | 14.4 | 14.4 | 42.2 | Trade-off: +193% tamanho |
| Tempo treino (h)      | 0.56 | 1.13 | 0.13 | GPU T4 muito mais eficiente |

**Principais Insights:**

1. **Impacto do Tempo de Treinamento:** Salto de 30 para 60 √©pocas no `YOLOv5s` elevou mAP@.50 geral de 0.393 para 0.513 (+30,5%), eliminando sinais de underfitting observados no experimento inicial. A classe `fork` beneficiou-se especialmente, saltando de 0.0999 para 0.262 (+162%).

2. **Impacto da Complexidade Arquitetural:** Migra√ß√£o para `YOLOv5m` elevou mAP@.50 geral para 0.789 (+53,8% sobre melhor modelo pequeno). Desempenho em `fork` mais que dobrou (0.262 ‚Üí 0.584), demonstrando que arquitetura mais robusta captura melhor nuances de objetos irregulares.

3. **Trade-off de Tamanho:** YOLOv5m apresenta aumento de ~200% no tamanho (14 MB ‚Üí 42 MB). Este custo deve ser considerado em:
   - Restri√ß√µes de armazenamento em dispositivos edge
   - Tempo de carregamento do modelo
   - Estrat√©gias de versionamento em MLOps
   - Largura de banda para deploy remoto

4. **Efici√™ncia de Hardware:** GPU T4 demonstrou throughput muito superior (0.13h vs 1.13h para 60 √©pocas), validando import√¢ncia de hardware adequado para experimenta√ß√£o √°gil.

**An√°lise Qualitativa:**
- Classe `banana`: Detec√ß√£o praticamente perfeita em todas as condi√ß√µes testadas
- Classe `fork`: Melhora significativa com YOLOv5m, mas ainda apresenta desafios em:
  - √Çngulos muito obl√≠quos
  - Fundos com texturas met√°licas similares
  - Oclus√µes parciais
- Limita√ß√£o de bounding boxes: Objetos irregulares capturam muito ru√≠do de fundo, sugerindo segmenta√ß√£o como evolu√ß√£o futura

### 5.2 Resultados da Entrega 2: YOLO vs CNN

**Comparativo Qualitativo:**

| Crit√©rio | YOLO Tradicional | CNN Customizada |
| -------- | ---------------- | --------------- |
| **Facilidade de uso** | Alta - ferramentas prontas, integra√ß√£o simplificada | M√©dia - requer implementa√ß√£o manual |
| **Precis√£o** | Alta para detec√ß√£o multi-objeto com localiza√ß√£o | Alta para classifica√ß√£o pura |
| **Tempo treinamento** | Moderado (60 √©pocas: ~1h CPU, 0.13h GPU) | R√°pido (60 √©pocas: menor devido √† simplicidade) |
| **Tempo infer√™ncia** | Otimizado para tempo real (~10-30ms por imagem) | Eficiente para classifica√ß√£o √∫nica |
| **Aplicabilidade** | Detec√ß√£o, localiza√ß√£o, contagem de objetos | Classifica√ß√£o bin√°ria/multi-classe |

**Conclus√µes da Compara√ß√£o:**
- **YOLOv5 superior quando**: Necess√°rio localizar objetos, detectar m√∫ltiplos objetos simultaneamente, aplica√ß√µes em tempo real
- **CNN adequada quando**: Apenas classifica√ß√£o necess√°ria, imagens pr√©-recortadas, recursos computacionais limitados para infer√™ncia simples
- **Trade-offs fundamentais**: Complexidade vs versatilidade, implementa√ß√£o vs performance

### 5.3 Resultados do Ir Al√©m 2: Pipeline Integrado

**Comparativo Quantitativo:**

| M√©trica | Baseline (MobileNetV2) | Pipeline Integrado (YOLO + MobileNetV2) | Delta |
| ------- | ---------------------: | ---------------------------------------: | ----: |
| **Acur√°cia** | 75.00% | **87.50%** | +12.50 |
| **Precis√£o** | 67.86% | **85.71%** | +17.86 |
| **Recall** | 100.00% | 75.00% | -25.00 |
| **F1-Score** | 80.95% | 80.00% | -0.95 |

**An√°lise de Trade-offs:**

1. **Ganho em Precis√£o (+17.86 pontos):**
   - Pipeline elimina muito ru√≠do de fundo atrav√©s do recorte inteligente
   - Classificador foca apenas na regi√£o relevante
   - Redu√ß√£o dr√°stica de falsos positivos
   - **Ideal para**: Aplica√ß√µes onde custo de falso positivo √© alto (ex: sistemas de seguran√ßa, controle de qualidade)

2. **Perda em Recall (-25 pontos):**
   - Falhas na detec√ß√£o YOLOv5 resultam em objetos n√£o classificados
   - Pipeline cascata amplifica erros da primeira etapa
   - **Mitiga√ß√£o**: Ajustar threshold de confian√ßa do YOLOv5 para m√°xima sensibilidade
   - **Trade-off consciente**: Aceitar mais falsos positivos no detector para maximizar recall final

3. **Estabilidade de F1-Score:**
   - F1-Score praticamente id√™ntico (80.95% vs 80.00%) indica rebalanceamento de erros
   - Mudan√ßa de perfil: menos falsos positivos, mais falsos negativos
   - Escolha de pipeline deve ser guiada por contexto de neg√≥cio

**Recomenda√ß√µes por Contexto:**

| Contexto | Pipeline Recomendado | Justificativa |
| -------- | ------------------- | ------------- |
| Controle de qualidade industrial | Pipeline Integrado | Alta precis√£o cr√≠tica; falsos positivos custosos |
| Triagem m√©dica inicial | Baseline | Recall 100% essencial; falsos positivos revisados por humanos |
| Sistema de seguran√ßa | Pipeline Integrado | Confiabilidade de alertas priorit√°ria |
| Monitoramento ambiental | Baseline | M√°xima cobertura para n√£o perder eventos raros |

### 5.4 An√°lise Consolidada das Tr√™s Entregas

**Progress√£o de Conhecimento:**
1. **Entrega 1**: Estabeleceu funda√ß√£o s√≥lida em detec√ß√£o, compreens√£o de trade-offs arquiteturais
2. **Entrega 2**: Expandiu compreens√£o comparando paradigmas diferentes (detec√ß√£o vs classifica√ß√£o)
3. **Ir Al√©m 2**: Demonstrou t√©cnicas avan√ßadas de integra√ß√£o e otimiza√ß√£o de pipelines

**Li√ß√µes Aprendidas:**
- N√£o existe modelo "melhor" universal - apenas modelo mais adequado para contexto espec√≠fico
- Trade-offs entre m√©tricas refletem decis√µes de engenharia, n√£o falhas
- Documenta√ß√£o detalhada e an√°lise quantitativa s√£o essenciais para decis√µes informadas
- Pipelines complexos oferecem oportunidades de otimiza√ß√£o mas introduzem pontos de falha adicionais

---

## **6.0 Recomenda√ß√µes Estrat√©gicas**

### 6.1 Recomenda√ß√µes por Cen√°rio de Deploy

**Cen√°rio 1: Ambientes com Recursos Amplos (Cloud/Desktop)**
- **Modelo Recomendado**: YOLOv5m (60 √©pocas)
- **Justificativa**: mAP@.50 de 0.789, excelente equil√≠brio entre acur√°cia e tempo de infer√™ncia
- **Tamanho**: 42.2 MB facilmente gerenci√°vel em infraestrutura cloud
- **Aplica√ß√µes**: Sistemas de monitoramento centralizados, processamento em lote, an√°lise retrospectiva
- **Melhorias Sugeridas**: 
  - Considerar YOLOv5l ou YOLOv5x para incremento adicional de acur√°cia
  - Implementar ensemble de modelos para m√°xima confiabilidade

**Cen√°rio 2: Dispositivos Embarcados (Edge com Restri√ß√µes)**
- **Modelo Recomendado**: YOLOv5s com otimiza√ß√µes
- **Justificativa**: 14.4 MB mais adequado para dispositivos com mem√≥ria limitada
- **Estrat√©gias de Otimiza√ß√£o**:
  - **Quantiza√ß√£o**: Converter de FP32 para INT8 (redu√ß√£o de ~75% em tamanho)
  - **Pruning**: Remover pesos menos importantes (redu√ß√£o adicional de 30-50%)
  - **Knowledge Distillation**: Treinar modelo menor com supervis√£o do YOLOv5m
- **Trade-off Esperado**: Manter 80-90% da acur√°cia do modelo grande
- **Aplica√ß√µes**: ESP32-CAM, Raspberry Pi, sistemas IoT, c√¢meras inteligentes

**Cen√°rio 3: Aplica√ß√µes Cr√≠ticas (Alta Precis√£o)**
- **Pipeline Recomendado**: YOLOv5m + MobileNetV2 (Ir Al√©m 2)
- **Justificativa**: Precis√£o de 85.71% minimiza falsos positivos
- **Aplica√ß√µes**: Controle de qualidade, sistemas de seguran√ßa, aplica√ß√µes m√©dicas
- **Considera√ß√µes**: Aceitar recall reduzido (75%) e maior lat√™ncia
- **Otimiza√ß√£o**: Ajustar threshold de confian√ßa do YOLOv5 conforme toler√¢ncia a falsos positivos

**Cen√°rio 4: M√°xima Cobertura (Alto Recall)**
- **Pipeline Recomendado**: Baseline direto (MobileNetV2) ou YOLO com threshold baixo
- **Justificativa**: Recall de 100% garante nenhum objeto perdido
- **Aplica√ß√µes**: Triagem inicial, monitoramento ambiental, sistemas de alerta
- **P√≥s-processamento**: Revis√£o humana de falsos positivos aceit√°vel

### 6.2 Roadmap de Evolu√ß√£o T√©cnica

**Curto Prazo (1-3 meses):**

1. **Expans√£o de Dataset**
   - Alvo: 200+ imagens por classe
   - Foco: Cen√°rios adversos (baixa ilumina√ß√£o, oclus√£o, m√∫ltiplos objetos)
   - Diversifica√ß√£o: Novos objetos, diferentes categorias
   
2. **Data Augmentation Avan√ßado**
   - T√©cnicas: Cutout, Copy-Paste, Mixup, CutMix
   - Ajustes: Cores (HSV), rota√ß√£o, scale, flip
   - Objetivo: Simular variabilidade real sem coleta adicional
   
3. **Avalia√ß√£o Autom√°tica**
   - Implementar pipeline de CI/CD para modelos
   - Alertas quando mAP@.50 < 0.70
   - Dashboards de monitoramento cont√≠nuo

**M√©dio Prazo (3-6 meses):**

1. **Otimiza√ß√£o de Hiperpar√¢metros**
   - Framework: Optuna ou Ray Tune
   - Par√¢metros: Learning rate, momentum, weight decay, augmentation intensity
   - Objetivo: Ganho de 5-10% em mAP@.50
   
2. **Segmenta√ß√£o de Inst√¢ncias**
   - Modelos: Mask R-CNN, YOLACT, YOLOv8-Seg
   - Objetivo: Superar limita√ß√£o de bounding boxes
   - M√©trica alvo: IoU (Intersection over Union) > 0.80
   
3. **Compress√£o de Modelos**
   - Pipeline: Pruning estruturado + Quantiza√ß√£o INT8 + ONNX Runtime
   - Objetivo: YOLOv5m com tamanho de YOLOv5s (~15 MB)
   - Restri√ß√£o: Manter mAP@.50 > 0.70

**Longo Prazo (6-12 meses):**

1. **MLOps e Governan√ßa**
   - Versionamento de dados: DVC (Data Version Control)
   - Tracking de experimentos: MLflow, Weights & Biases
   - CI/CD para modelos: GitHub Actions + Model Registry
   - Monitoramento p√≥s-deploy: Drift detection, performance degradation alerts
   
2. **Integra√ß√£o com Sistemas FarmTech**
   - APIs REST/gRPC para infer√™ncia
   - Dashboards executivos com m√©tricas de neg√≥cio
   - Integra√ß√£o com sistemas legados (ERP, CRM)
   - Feedback loop: Predi√ß√µes ‚Üí Valida√ß√£o ‚Üí Retreinamento
   
3. **Expans√£o de Capacidades**
   - Detec√ß√£o de m√∫ltiplas classes (10+ objetos)
   - Rastreamento de objetos (tracking) em v√≠deo
   - An√°lise temporal: Contagem, comportamento, padr√µes
   - Modelos especializados por contexto (indoor vs outdoor, dia vs noite)

### 6.3 Governan√ßa de Dados e Compliance

**Qualidade de Dados:**
- **Checklist de Valida√ß√£o**:
  ‚úì Formatos de imagem padronizados (JPEG/PNG)
  ‚úì Resolu√ß√£o m√≠nima (640x640 pixels)
  ‚úì Anota√ß√µes validadas por segundo revisor
  ‚úì Metadados completos (timestamp, condi√ß√µes de captura)
  
- **Auditoria de Rotulagem**:
  - Revis√£o peri√≥dica de 10% das anota√ß√µes
  - Inter-annotator agreement (Cohen's Kappa > 0.80)
  - Re-anota√ß√£o de casos amb√≠guos

**Reprodutibilidade:**
- **Registro de Experimentos**:
  - Par√¢metros de treinamento (√©pocas, learning rate, batch size)
  - Hardware utilizado (CPU/GPU, mem√≥ria)
  - Seed aleat√≥rio para reprodu√ß√£o exata
  - Timestamp e identificador √∫nico
  
- **Controle de Vers√µes**:
  - Dataset: Vers√£o, data, autor, changelog
  - Modelo: Arquitetura, pesos, m√©tricas, data de treino
  - C√≥digo: Git commits, tags de release

**Seguran√ßa e Privacidade:**
- Dataset propriet√°rio com controle de acesso (Google Drive com permiss√µes)
- Dados sens√≠veis n√£o devem ser inclu√≠dos em imagens
- Anonimiza√ß√£o de metadados quando necess√°rio
- Backup regular (3-2-1: 3 c√≥pias, 2 m√≠dias diferentes, 1 offsite)

### 6.4 M√©tricas de Sucesso do Projeto

**M√©tricas T√©cnicas:**
- ‚úÖ mAP@.50 > 0.70 (Alcan√ßado: 0.789)
- ‚úÖ Tempo de infer√™ncia < 100ms (Alcan√ßado: ~30ms)
- ‚úÖ Modelo < 50 MB para deploy (YOLOv5m: 42.2 MB)
- ‚úÖ Dataset > 80 imagens (Exato: 80 imagens)

**M√©tricas de Processo:**
- ‚úÖ Documenta√ß√£o completa e reprodut√≠vel
- ‚úÖ Notebooks execut√°veis com c√©lulas narrativas
- ‚úÖ V√≠deos demonstrativos publicados
- ‚úÖ C√≥digo versionado no GitHub

**M√©tricas de Neg√≥cio (Projetadas):**
- Redu√ß√£o de 50% em tempo de inspe√ß√£o manual (estimativa)
- Acur√°cia compar√°vel ou superior a humanos (classe `banana`: 99.5%)
- ROI positivo em 6 meses de opera√ß√£o (proje√ß√£o)
- Escalabilidade para 10+ classes sem re-arquitetura

### 6.5 Pr√≥ximos Passos Imediatos

1. **Semana 1-2**: Expandir dataset para 120 imagens (50% increase)
2. **Semana 3-4**: Implementar data augmentation e retreinar modelos
3. **M√™s 2**: Iniciar POC de segmenta√ß√£o de inst√¢ncias
4. **M√™s 3**: Desenvolver API REST para infer√™ncia em produ√ß√£o
5. **Trimestre 2**: Integra√ß√£o com primeiro cliente piloto da FarmTech

---

## **7.0 Conclus√£o**

Este projeto demonstrou com sucesso a viabilidade t√©cnica de solu√ß√µes de vis√£o computacional para a FarmTech Solutions atrav√©s de tr√™s entregas complementares. A jornada desde detec√ß√£o b√°sica (Entrega 1), passando por an√°lise comparativa (Entrega 2), at√© pipeline avan√ßado integrado (Ir Al√©m 2) proporcionou compreens√£o profunda de trade-offs, limita√ß√µes e oportunidades em diferentes arquiteturas de Deep Learning.

**Principais Conquistas:**
- Pipeline completo de MLOps desde aquisi√ß√£o de dados at√© infer√™ncia em produ√ß√£o
- Documenta√ß√£o executiva detalhada alinhada com requisitos da Fase 6 da FIAP
- An√°lise quantitativa e qualitativa de m√∫ltiplas arquiteturas e abordagens
- Demonstra√ß√£o pr√°tica de transfer learning e integra√ß√£o de modelos

**Impacto para FarmTech Solutions:**
O projeto estabeleceu funda√ß√£o s√≥lida para expans√£o de servi√ßos de IA da empresa, validando capacidade t√©cnica da equipe e demonstrando ao cliente fict√≠cio o potencial de vis√£o computacional. As recomenda√ß√µes estrat√©gicas fornecem roadmap claro para evolu√ß√£o de POC para produto comercial.

**Alinhamento com Orienta√ß√µes da Fase 6:**
Todas as metas e entreg√°veis especificados no [`orientation.md`](orientation.md) foram cumpridos integralmente:
- ‚úÖ Dataset com 80 imagens (40 por classe)
- ‚úÖ Divis√£o estratificada 80/10/10
- ‚úÖ Rotula√ß√£o no Make Sense AI
- ‚úÖ M√∫ltiplas simula√ß√µes com diferentes √©pocas
- ‚úÖ Notebooks com c√≥digo executado e c√©lulas Markdown
- ‚úÖ V√≠deos demonstrativos no YouTube (n√£o listados)
- ‚úÖ README integrado com notebooks
- ‚úÖ Reposit√≥rio GitHub p√∫blico

Este trabalho representa n√£o apenas uma entrega acad√™mica, mas uma demonstra√ß√£o profissional de capacidade de execu√ß√£o end-to-end de projetos de Machine Learning, desde concep√ß√£o at√© recomenda√ß√µes estrat√©gicas para produ√ß√£o.
